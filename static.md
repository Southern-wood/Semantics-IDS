## SWaT 基础实验

| Quality Type        |  GDN   | Our Model | PASAD  | DCdetector |  USAD  |  SFIG  | CNN AE |
| ------------------- | ------ | --------- | ------ | ---------- | ------ | ------ | ------ |
| SWaT pure           | 0.7780 |  0.9624   | 0.7430 |   0.9641   | 0.8048 | 0.9441 | 0.2689 |
| SWaT noise low      | 0.6847 |  0.9581   | 0.7430 |   0.9633   | 0.7996 | 0.3592 | 0.2570 |
| SWaT noise high     | 0.7712 |  0.9588   | 0.7508 |   0.9640   | 0.8371 | 0.2465 | 0.2889 |
| SWaT missing low    | 0.4921 |  0.9670   | 0.7508 |   0.9640   | 0.8476 | 0.2441 | 0.4078 |
| SWaT missing high   | 0.4506 |  0.9528   | 0.7508 |   0.9094   | 0.8543 | 0.2178 | 0.9036 |
| SWaT duplicate low  | 0.7566 |  0.9592   | 0.7508 |   0.9641   | 0.8675 | 0.2178 | 0.8841 |
| SWaT duplicate high | 0.4994 |  0.9588   | 0.7602 |   0.9596   | 0.8481 | 0.2669 | 0.8597 |
| SWaT delay low      | 0.4295 |  0.9357   | 0.7602 |   0.9451   | 0.8531 | 0.2701 | 0.8404 |
| SWaT delay high     | 0.4578 |  0.9405   | 0.7602 |   0.9630   | 0.8461 | 0.2693 | 0.8693 |
| SWaT mismatch low   | 0.6938 |  0.9443   | 0.7602 |   0.9629   | 0.8396 | 0.2491 | 0.8647 |
| SWaT mismatch high  | 0.7523 |  0.9471   | 0.7602 |   0.9639   | 0.8419 | 0.3774 | 0.8993 |
| SWaT mix 1 low      | 0.7861 |  0.9782   | 0.7443 |   0.9632   | 0.7991 |        | 0.2788 |
| SWaT mix 1 high     | 0.4474 |  0.9692   | 0.7619 |   0.9231   | 0.8160 |        | 0.2289 |
| SWaT mix 2 low      | 0.7997 |  0.9740   | 0.7420 |   0.8755   | 0.8710 |        | 0.4949 |
| SWaT mix 2 high     | 0.4967 |  0.9680   | 0.7881 |   0.9500   | 0.7644 |        | 0.3599 | 

Our Model 在 5 种低质量数据场景下能和 DCdetctor 取得大致相当的性能，在 delay 和 mismatch 上的性能有一定损失，这可能是因为 DCdetector 设计了长度为 105 的 windows，能够更好对抗 delay（时间片固定偏移） 和 mismatch （采样率不一致） 带来的影响，而我们的模型由于 AutoDis 和时空间相关性设计占用了较高的显存资源，在我们的实验环境下只能采用 windows = 10，对抗这两种场景的能力略有损失；并且，由于这两种场景实际上并没有完全“破坏”数据的时序特征，只是增大了学习时序特征的难度，因此我们模型的鲁棒性设计在这两种场景下也没有发挥出优势。

在我们设置的更真实的噪声场景下（mix 1 和 mix 2），我们的模型对比 DCdetector 的优势比较明显，这是可能是因为更复杂的场景下，低质量的数据特征将显著地破坏数据的时序关系，这种场景下去除噪声的能力将主导模型的性能，DCdetector 的对比学习设计具有一定的去噪能力，但可能不能对抗太复杂的场景，而我们模型的鲁棒性设计可以发挥优势。

额外发现：真实场景下 CNN-AE 和 USAD 的性能提升相对有限，mix 1 上基本上没有性能反常提升，mix 2 的 high 上提升也很有限。

## 额外实验

针对 USAD 在 SWaT 上性能提升 / DCdetector 在 SWaT 上性能不降，详细列出各个噪声下 Precision 和 Recall 的细分结果。

| Quality Type        | USAD F1 | Our F1  | DC F1   | USAD Pre | Our Pre | DC Pre  | USAD Rec | Our Rec | DC Rec  |
|---------------------|---------|---------|---------|----------|---------|---------|----------|---------|---------|
| SWaT pure           | 0.8048  | 0.9624  | 0.9640  | 0.9924   | 0.9449  | 0.9309  | 0.6724   | 0.9806  | 0.9996  |
| SWaT noise 1      | 0.7996  | 0.9581  | 0.9633  | 0.9859   | 0.9510  | 0.9315  | 0.6724   | 0.9654  | 0.9996  |
| SWaT noise 2     | 0.8371  | 0.9588  | 0.9640  | 0.9766   | 0.9633  | 0.9315  | 0.7324   | 0.9543  | 0.9974  |
| SWaT missing low    | 0.8476  | 0.9670  | 0.9640  | 0.9343   | 0.9523  | 0.9327  | 0.7756   | 0.9822  | 0.9974  |
| SWaT missing high   | 0.8543  | 0.9528  | 0.9094  | 0.9845   | 0.9770  | 0.9119  | 0.7546   | 0.9298  | 0.8982  |
| SWaT duplicate low  | 0.8675  | 0.9592  | 0.9641  | 0.9833   | 0.9362  | 0.9311  | 0.7761   | 0.9834  | 0.9996  |
| SWaT duplicate high | 0.8550  | 0.9588  | 0.9596  | 0.9596   | 0.9405  | 0.9307  | 0.7597   | 0.9778  | 0.9904  |
| SWaT delay low      | 0.8404  | 0.9357  | 0.9451  | 0.9656   | 0.9448  | 0.9272  | 0.7439   | 0.9268  | 0.9637  |
| SWaT delay high     | 0.8435  | 0.9405  | 0.9630  | 0.9738   | 0.9677  | 0.9307  | 0.7439   | 0.9148  | 0.9977  |
| SWaT mismatch low   | 0.8274  | 0.9443  | 0.9632  | 0.9611   | 0.9506  | 0.9309  | 0.7626   | 0.9381  | 0.9977  |
| SWaT mismatch high  | 0.8385  | 0.9471  | 0.9647  | 0.9560   | 0.9633  | 0.9322  | 0.7468   | 0.9315  | 0.9996  |
| SWaT mix 1 low      | 0.7991  | 0.9782  | 0.9641  | 0.9845   | 0.9782  | 0.9310  | 0.6725   | 0.9783  | 0.9996  |
| SWaT mix 1 high     | 0.8161  | 0.9692  | 0.9231  | 0.9646   | 0.9712  | 0.8952  | 0.7071   | 0.9672  | 0.9528  |
| SWaT mix 2 low      | 0.8710  | 0.9680  | 0.8755  | 0.9477   | 0.9400  | 0.9151  | 0.8059   | 0.9976  | 0.8391  |
| SWaT mix 2 high     | 0.7644  | 0.9657  | 0.9500  | 0.9464   | 0.9520  | 0.9301  | 0.7109   | 0.9799  | 0.9709  |


结论：

- 主要因为 USAD 是一个高 precision，低 recall 的模型，在 pure 环境下实际上有大量的攻击并没有被检测到，低质量数据中，部分异常数据的重构误差更大，USAD 将部分原本无法被检测的异常检出，结合 point adjust 的特性（乐观估计 recall），导致了 USAD 在低数据质量场景下整体 F1 上升。

- DCdetector 则是一个高 recall，（相对）低 precision 的模型，并且受益于对比学习架构，它能保持在大部分低数据质量场景下的 recall 并不下降，在 point adjust 下，只要保持高 recall，precision 的下降总是有限的，因此在 F1 统计上 DCdetctor 性能下降不明显。

- 我们的模型总体上介于两者之间，precision 降序排名：USAD、Our Model、DCdetctor；recall 降序排名：DCdetector、Our Model、USAD. 

问题：

- 最后一点是否可以解释为一个优势？我们在 precision 和 recall 之间取得了一个更好的平衡之类的。

- 是否单独解释 USAD 就可以了？CNN-AE 也可以解释，但是情况和 USAD 又不一样，特殊情况太多了（PASAD、USAD、CNN-AE）感觉可信度会下降，直接说我们选取其中一个做了 case study，回避 CNN-AE 的提升是否也可以？

- Our Model 阈值选取 / 时间消耗

CNN-AE 的情况比较复杂，原始数据上 CNN-AE 的 recall 非常高，precision 很低，噪声提高的时候 precision 是提高的，recall 的下降不太明显。

需要解释的话，这应该和 CNN-AE 的阈值确定方法有关系（CUSUM），它使用的 CUSUM 是设置累计的偏移上限和下限来确定阈值的，pure 情况下 CUSUM 的上限下限都很小，因为都是正常的数据，波动不大，所以它确定的阈值应用到实际的攻击数据上就导致了大量的误报。

在低数据质量的数据集上训练 + 确定阈值，会扩大 CUSUM 的上下限，这一点会让 CNN-AE 的 precision 大幅度上升（即误报率明显减少）。

## WADI 和 HAI 基础实验

| Quality Type        |  GDN   | Our Model | PASAD  | DCdetector |  USAD  |  SFIG  | CNN AE |
| ------------------- | ------ | --------- | ------ | ---------- | ------ | ------ | ------ |
| WADI pure           | 0.5163 |  0.7374   | 0.4402 |   0.7143   | 0.1437 | 0.5318 | 0.1467 |
| WADI noise low      | 0.1917 |  0.8473   | 0.1519 |   0.6529   | 0.0942 | 0.0945 | 0.1018 |
| WADI noise high     | 0.1836 |  0.8269   | 0.1518 |   0.7061   | 0.0942 | 0.0937 | 0.1073 |
| WADI missing low    | 0.1799 |  0.8246   | 0.1518 |   0.6014   | 0.0942 | 0.0937 | 0.1045 |
| WADI missing high   | 0.3009 |  0.8880   | 0.4438 |   0.5952   | 0.0942 |    0   | 0.1039 |
| WADI duplicate low  | 0.1606 |  0.9092   | 0.4445 |   0.6614   | 0.0942 | 0.0933 | 0.1056 |
| WADI duplicate high | 0.1637 |  0.9186   | 0.4402 |   0.7060   | 0.0944 | 0.0933 | 0.1066 |
| WADI delay low      | 0.1520 |  0.8324   | 0.4403 |   0.7175   | 0.0944 | 0.0933 | 0.1053 |
| WADI delay high     | 0.1629 |  0.9334   | 0.4393 |   0.6560   | 0.0944 |    0   | 0.1067 |
| WADI mismatch low   | 0.3767 |  0.9333   | 0.4433 |   0.6855   | 0.0942 | 0.0935 | 0.1017 |
| WADI mismatch high  | 0.1501 |  0.9126   | 0.4433 |   0.6816   | 0.0942 | 0.0978 | 0.1075 |
| WADI mix 1 low      | 0.5233 |  0.8311   | 0.4401 |   0.6911   | 0.0574 |        | 0.1461 |
| WADI mix 1 high     | 0.1789 |  0.9121   | 0.1519 |   0.7163   | 0.1392 |        | 0.1084 |
| WADI mix 2 low      | 0.5148 |  0.7014   | 0.4401 |   0.6767   | 0.0607 |        | 0.1467 |
| WADI mix 2 high     | 0.4376 |  0.8508   | 0.4458 |   0.6514   | 0.0638 |        | 0.1110 |


| Quality Type       | GDN    | Our Model | PASAD  | DCdetector | USAD   | SFIG   | CNN AE |
| ------------------ | ------ | --------- | ------ | ---------- | ------ | ------ | ------ |
| HAI pure           | 0.8668 | 0.9841    | 0.4770 | 0.5906     | 0.1667 | 0.9890 | 0.5456 |
| HAI noise low      | 0.8120 | 0.9648    | 0.4770 | 0.7549     | 0.1664 | 0.0876 | 0.4927 |
| HAI noise high     | 0.7895 | 0.9774    | 0.4750 | 0.6598     | 0.1638 | 0.0763 | 0.5506 |
| HAI missing low    | 0.8326 | 0.9784    | 0.3281 | 0.6718     | 0.1632 | 0.0763 | 0.5647 |
| HAI missing high   | 0.6922 | 0.9821    | 0.4357 | 0.6911     | 0.1599 | 0.0766 | 0.5647 |
| HAI duplicate low  | 0.5372 | 0.9824    | 0.4358 | 0.6644     | 0.1600 | 0.0766 | 0.5638 |
| HAI duplicate high | 0.5052 | 0.9542    | 0.4358 | 0.5439     | 0.1598 | 0.0806 | 0.5062 |
| HAI delay low      | 0.2068 | 0.9182    | 0.4358 | 0.5967     | 0.1598 | 0.0806 | 0.5058 |
| HAI delay high     | 0.1869 | 0.9126    | 0.4349 | 0.6587     | 0.1608 | 0.0806 | 0.5051 |
| HAI mismatch low   | 0.1412 | 0.9116    | 0.4349 | 0.5880     | 0.1608 | 0.0806 | 0.5054 |
| HAI mismatch high  | 0.2021 | 0.9040    | 0.3216 | 0.6276     | 0.1485 | 0.6950 | 0.5222 |
| HAI mix 1 low      | 0.8518 | 0.9610    | 0.4770 | 0.5637     | 0.1302 |        | 0.5276 |
| HAI mix 1 high     | 0.5912 | 0.9591    | 0.4769 | 0.5159     | 0.1312 |        | 0.4812 |
| HAI mix 2 low      | 0.8546 | 0.9661    | 0.4770 | 0.6264     | 0.1298 |        | 0.4099 |
| HAI mix 2 high     | 0.6836 | 0.9552    | 0.4769 | 0.5905     | 0.1349 |        | 0.3648 |

WADI 和 HAI 上情况类似，由于 DCdetector 并没有在 WADI 或者 HAI 上做评估，因此我们采用的是 DCdetector 在官方实现中的默认参数作为对比，其他的模型也都一样，有数据集对应参数的直接用论文提供的，没有对应参数的，采用官方实现中的默认参数（如果没有，则复制 SWaT 的参数）作为对比。

这两个数据集上都能 Sota，且除了我们自己的模型在 WADI 的低数据质量场景上取得了性能的提升外，基本上没有其他的异常提升。

SFIG 这个方法有点特别，在 HAI 的 pure 上能跑出 F1=0.980，不过在所有低质量的数据上几乎都被完全破坏，并且在 WADI 的某些场景下跑三四天都跑不出来（标 0 的几个），因为训练速度太慢，mix 场景还没来得及跑出来。

## SWaT Cross-Level Performance

> 这里只更新了 GDN/Our Model/DCdetector/UASD 的结果，其他的模型还是原来的结果

| Quality Type (Cross)| GDN    | Our Model | PASAD  | DCdetector | USAD   | SFIG   | CNN AE |
| ------------------- | ------ | --------- | ------ | ---------- | ------ | ------ | ------ |
| SWaT pure           | 0.7780 | 0.9624    | 0.7430 | 0.9641     | 0.8048 | 0.9441 | 0.2689 |
| SWaT noise low      | 0.6847 | 0.9504    | 0.7430 | 0.9652     | 0.8403 | 0.3592 | 0.2570 |
| SWaT noise high     | 0.7712 | 0.9383    | 0.7508 | 0.9635     | 0.8085 | 0.2465 | 0.2889 |
| SWaT missing low    | 0.4921 | 0.9628    | 0.7508 | 0.9632     | 0.6220 | 0.2441 | 0.4078 |
| SWaT missing high   | 0.4506 | 0.9757    | 0.7508 | 0.9208     | 0.8486 | 0.2178 | 0.9036 |
| SWaT duplicate low  | 0.7566 | 0.9492    | 0.7508 | 0.9643     | 0.8489 | 0.2178 | 0.8841 |
| SWaT duplicate high | 0.4994 | 0.9554    | 0.7602 | 0.9483     | 0.8550 | 0.2669 | 0.8597 |
| SWaT delay low      | 0.4295 | 0.9436    | 0.7602 | 0.9507     | 0.8404 | 0.2701 | 0.8404 |
| SWaT delay high     | 0.4578 | 0.9489    | 0.7602 | 0.9644     | 0.8469 | 0.2693 | 0.8693 |
| SWaT mismatch low   | 0.6938 | 0.9415    | 0.7602 | 0.9632     | 0.8344 | 0.2491 | 0.8647 |
| SWaT mismatch high  | 0.7523 | 0.9373    | 0.7834 | 0.9648     | 0.8352 | 0.3774 | 0.8993 |
| SWaT mix 1 low      | 0.7861 | 0.9232    | 0.7443 | 0.9647     | 0.8440 |        | 0.2788 |
| SWaT mix 1 high     | 0.4474 | 0.9397    | 0.7619 | 0.8646     | 0.8130 |        | 0.2289 |
| SWaT mix 2 low      | 0.7997 | 0.9634    | 0.7420 | 0.9214     | 0.8805 |        | 0.4949 |
| SWaT mix 2 high     | 0.4967 | 0.9614    | 0.7881 | 0.9114     | 0.5657 |        | 0.3599 |

结论基本一致，我们的模型可以在 SWaT 的基础低质量场景上大致和 DCdetctor 打平或者略逊色，在 mix 上比 DCdetector 优秀，对比方法是不是会下降得更低

> 以下只更新了 GDN/USAD/DCdetector


| Quality Type (Cross)| GDN    | Our Model | PASAD  | DCdetector | USAD   | SFIG   | CNN AE |
| ------------------- | ------ | --------- | ------ | ---------- | ------ | ------ | ------ |
| WADI pure           | 0.5163 | 0.7487    | 0.4402 | 0.7143     | 0.1437 | 0.5318 | 0.1467 |
| WADI noise low      | 0.1655 | 0.8824    | 0.1519 | 0.6954     | 0.0942 | 0.0945 | 0.1018 |
| WADI noise high     | 0.2648 | 0.9000    | 0.1518 | 0.5078     | 0.0942 | 0.0937 | 0.1073 |
| WADI missing low    | 0.1635 | 0.8988    | 0.1518 | 0.6865     | 0.0942 |        | 0.1045 |
| WADI missing high   | 0.1734 | 0.8973    | 0.4438 | 0.6047     | 0.0942 |        | 0.1039 |
| WADI duplicate low  | 0.1442 | 0.8965    | 0.4445 | 0.4677     | 0.0962 |        | 0.1056 |
| WADI duplicate high | 0.1608 | 0.7719    | 0.4402 | 0.4941     | 0.0944 |        | 0.1066 |
| WADI delay low      | 0.1587 | 0.7997    | 0.4403 | 0.7167     | 0.0944 |        | 0.1053 |
| WADI delay high     | 0.1588 | 0.9334    | 0.4393 | 0.6941     | 0.0944 |        | 0.1067 |
| WADI mismatch low   | 0.1362 | 0.9333    | 0.4433 | 0.6005     | 0.0942 |        | 0.1017 |
| WADI mismatch high  | 0.1489 | 0.9126    | 0.4433 | 0.4228     | 0.0944 |        | 0.1075 |
| WADI mix 1 low      | 0.1801 | 0.8311    | 0.4401 | 0.5889     | 0.0942 |        | 0.1461 |
| WADI mix 1 high     | 0.5241 |           | 0.1519 | 0.4684     | 0.1395 |        | 0.1084 |
| WADI mix 2 low      | 0.1679 | 0.7014    | 0.4401 | 0.5714     | 0.1248 |        | 0.1467 |
| WADI mix 2 high     | 0.5016 | 0.8508    | 0.4458 | 0.4254     | 0.1409 |        | 0.1110 |


| Quality Type(Cross)| GDN    | Our Model | PASAD  | DCdetector | USAD   | SFIG   | CNN AE |
| ------------------ | ------ | --------- | ------ | ---------- | ------ | ------ | ------ |
| HAI pure           | 0.8668 | 0.9841    | 0.4770 | 0.5906     | 0.1667 |        | 0.5456 |
| HAI noise low      | 0.7387 | 0.9648    | 0.4770 | 0.4098     | 0.1284 |        | 0.4927 |
| HAI noise high     | 0.7924 | 0.9774    | 0.4750 | 0.4070     | 0.1667 |        | 0.5506 |
| HAI missing low    | 0.2625 | 0.9784    | 0.3281 | 0.8502     | 0.0768 | 0.4488 | 0.5647 |
| HAI missing high   | 0.8273 | 0.9821    | 0.4357 | 0.4690     | 0.1604 | 0.4488 | 0.5647 |
| HAI duplicate low  | 0.1986 | 0.9824    | 0.4358 | 0.4779     | 0.1599 | 0.4488 | 0.5638 |
| HAI duplicate high | 0.2044 | 0.9542    | 0.4358 | 0.4671     | 0.1598 | 0.4488 | 0.5062 |
| HAI delay low      | 0.2761 | 0.9182    | 0.4358 | 0.6657     | 0.1609 | 0.4488 | 0.5058 |
| HAI delay high     | 0.3409 | 0.9126    | 0.4349 | 0.6500     | 0.1597 | 0.4488 | 0.5051 |
| HAI mismatch low   | 0.1432 | 0.9116    | 0.4349 | 0.6763     | 0.1497 | 0.4158 | 0.5054 |
| HAI mismatch high  | 0.2021 | 0.9040    | 0.3216 | 0.4894     | 0.1387 | 0.2500 | 0.5222 |
| HAI mix 1 low      | 0.7763 | 0.9610    | 0.4770 | 0.4648     | 0.1551 |        | 0.5276 |
| HAI mix 1 high     | 0.7797 | 0.9591    | 0.4770 | 0.6026     | 0.1665 |        | 0.4812 |
| HAI mix 2 low      | 0.1322 | 0.9661    | 0.4770 | 0.5449     | 0.0767 |        | 0.4099 |
| HAI mix 2 high     | 0.6721 | 0.9552    | 0.4770 | 0.5812     | 0.0853 |        | 0.3648 |


1. Cross 关注其他 baseline 下降的情况，我们是维持的。
2. 考虑归类，如果不行就取部分较差。


## 论文

1. problems statement，我们要做
